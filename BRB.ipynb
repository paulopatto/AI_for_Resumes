{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY5PCzbjA3tIGWNizI/vjG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulopatto/AI_for_Resumes/blob/master/BRB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Be Right Back (BRB)\n",
        "\n",
        "Criando uma versão virtual e análise sobre personalidade com base em dados de redes sociais."
      ],
      "metadata": {
        "id": "RiNg-KnOjIpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introdução: Revivendo Conversas com Agentes LLM Inspirados em \"Be Right Back\"\n",
        "\n",
        "O luto é uma experiência universal e complexa, marcada pela dor da perda e pelo desejo de manter a conexão com aqueles que se foram. O episódio \"[Be Right Back](https://en.wikipedia.org/wiki/Be_Right_Back) (S2E1)\" da série Black Mirror explora essa temática de forma inquietante e reflexiva, apresentando um futuro onde a tecnologia permite a criação de replicas virtuais de pessoas falecidas a partir de suas mídias sociais e dados pessoais.\n",
        "\n",
        "Inspirados por essa ficção científica, embarcamos em um projeto ambicioso: a criação de um sistema de agentes LLM (Large Language Models) capaz de imitar padrões conversacionais de indivíduos com base em seus históricos de interação em plataformas online, como WhatsApp e redes sociais. Através da integração de modelos de linguagem avançados como Gemini Pro, CrewAI e Longchain, nosso objetivo é desenvolver um sistema que permita:\n",
        "\n",
        "- **Recriar conversas ou simular conversas**: O sistema será capaz de analisar logs de conversas do WhatsApp ~~e outros canais online~~(melhoria futura) para capturar o estilo, vocabulário e tom de voz do usuário, permitindo a geração de novas conversas que simulam a sua presença.\n",
        "- **Manter a conexão**: Ao oferecer a possibilidade de interagir com uma versão virtual  da pessoa, no caso proposto na série, com uma versão virtual do falecido, o sistema visa auxiliar no processo de luto, fornecendo um espaço para compartilhar memórias, expressar sentimentos e manter viva a lembrança da pessoa amada. Porém este projeto entende que isso pode trazer um prolongamento do sofrimento do luto e pode ser usado em situções onde uma pessoa VIVA possa quere colocar uma versão virtual de si para responder mensganes e fazer tarefas do dia-a-dia.\n",
        "\n",
        "### Considerações Éticas\n",
        "\n",
        "O desenvolvimento de um sistema como este levanta importantes questões éticas que precisam ser cuidadosamente ponderadas. É fundamental garantir que a tecnologia seja utilizada de forma responsável e respeitosa, evitando a manipulação emocional dos usuários e a perpetuação de crenças falsas sobre a consciência ou imortalidade.\n",
        "Outras obras do cinema como [Transcendente - A revolução](https://en.wikipedia.org/wiki/Transcendence_(2014_film))"
      ],
      "metadata": {
        "id": "KZ-4aHY2k7LG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gerando dados para treinamento dos agentes\n",
        "\n",
        "Para que nossos agentes (crew) possam aprender como você (ou a pessoa que você quer análisar) falam, vamos precisar pegar um padrão conversacional e para  imitar e/ou gerar uma linguagem humana de forma natural e envolvente e para que nossos agentes alcancem o máximo potencial, é crucial treinalo com dados de  alta qualidade e onde a pessoal se mostrou de forma mais natural para o propósito da aplicação. É aí que entra a riqueza de informações contida nas conversas do aplicativo WhatsApp (mas relaxa em nossa versão Google Colab, você vai fazer isso dentro do seu Google Drive e você só vai compartilhar suas informações com o Gemini do Google).\n",
        "\n",
        "\n",
        "### Exportando Conversas do WhatsApp (dump)\n",
        "\n",
        "#### Conversas especificas\n",
        "\n",
        "Poder ser que vocẽ queira compartilhar apenas alguns contextos e por isso pode escolher as conversas que vai exportar, para isso tanto em Android como iPhone seiga esses passos:\n",
        "\n",
        "- Abra o WhatsApp e acesse a conversa desejada.\n",
        "- Toque nos três pontos no canto superior direito da tela.\n",
        "- Selecione \"Mais\" > \"Exportar conversa\".\n",
        "- Escolha entre \"Sem arquivos\" ou \"Incluir arquivos de mídia\".\n",
        "- Confirme a exportação e selecione o local para salvar o arquivo (TXT).\n",
        "\n",
        "#### Utilizando Backups Existentes\n",
        "\n",
        "Essa opção vai pegar todo o universo conversacional do Whatsapp nos mais diversos contextos, pode ser mais arriscado mas é a mais rica, lembra na série quando a Martha compsrtilha todo o arquivo de e-mails do Ash em como ele fica bem melhor? Pois é.\n",
        "\n",
        "**Na plataforma Google Android você pode seguir:**\n",
        "\n",
        "- Localize o arquivo de backup do WhatsApp (geralmente em `Armazenamento Interno > WhatsApp > Databases`).\n",
        "- Extraia o arquivo de backup usando um software de extração.\n",
        "- Acesse a pasta \"msgstore.db\" dentro do backup extraído.\n",
        "- Utilize ferramentas específicas (como o SQLite Viewer) para abrir e exportar as conversas desejadas.\n",
        "\n",
        "**Na plataforma Apple iPhone**\n",
        "\n",
        "- Conecte o iPhone ao computador e abra o iTunes.\n",
        "- Selecione o dispositivo e clique em \"Backup Agora\".\n",
        "- Localize o backup do WhatsApp no computador (geralmente em `Usuários > ${Nome do Usuário} > AppData > Roaming > Apple Computer > MobileSync > Backup`).\n",
        "- Extraia o arquivo de backup usando um software de extração.\n",
        "- Acesse a pasta \"ChatDatabase.sqlite\" dentro do backup extraído.\n",
        "- Utilize ferramentas específicas (como o SQLite Viewer) para abrir e exportar as conversas desejadas.\n",
        "\n",
        "(*) Sei que ficou bem nerd e isso pode melhor muito no processo\n",
        "\n",
        "\n",
        "### Organizando para subir\n",
        "\n",
        "Coloque todas as conversas (*.txt) exportadas pelo dump em uma mesma pasta, não vamos compactar pois em alguns testes a compactação não ficou legal, mas isso pode ser corrigido no futuro.\n",
        "\n",
        "**Versão Google Colab**\n",
        "\n",
        "Na versão Google colab você pode subir para a pasta de arquivos temposários com o nome da pasta como `Conversas`\n",
        "\n",
        "**Versão StandAlone python**\n",
        "\n",
        "Ainda não sei como seria a melhor forma!\n",
        "\n",
        "\n",
        "Feito isso vamos rodar o modelo!"
      ],
      "metadata": {
        "id": "TiO56VH97acY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desenvolvimento\n",
        "\n",
        "O desenvolviment"
      ],
      "metadata": {
        "id": "xDW2fF496Qy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Env\n",
        "\n",
        "- Install Libs\n",
        "- Setup APIKEY\n",
        "- Setup Model com Longchain"
      ],
      "metadata": {
        "id": "AOleuoXe6nTH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Na28-h942fSC"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai crewai langchain_google_genai crewai[tools]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "LLM_MODEL = 'gemini-pro'\n",
        "GEMINI_API_KEY=userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "model = genai.GenerativeModel(LLM_MODEL)\n",
        "#response = model.generate_content(\"Write a story about a magic backpack.\")\n",
        "#print(response.text)\n"
      ],
      "metadata": {
        "id": "gMMojWBG2wku"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "  model=LLM_MODEL,\n",
        "  verbose = True,\n",
        "  temperature = 0.6,\n",
        "  google_api_key=GEMINI_API_KEY\n",
        ")\n",
        "\n",
        "# Check if chats_folder exists, if no creates it\n",
        "chats_folder = '/content/Conversas'\n",
        "if not os.path.isdir(chats_folder):\n",
        "  os.mkdir(chats_folder)"
      ],
      "metadata": {
        "id": "XFHN8PMl5-aN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agentes\n",
        "\n",
        "Criação dos agentes"
      ],
      "metadata": {
        "id": "7MJSgF6c6aN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Profilers\n",
        "\n"
      ],
      "metadata": {
        "id": "JBcE2kL666Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from crewai_tools import DirectoryReadTool\n",
        "\n",
        "readDirectoryTool = DirectoryReadTool(directory=chats_folder)\n",
        "profiler_agent = Agent(\n",
        "  role='Analista de perfil',\n",
        "  goal=f\"\"\"\n",
        "  Dado um conjunto de mensagens de texto\n",
        "  E dado um determinado Ator\n",
        "  Ler mensagens as de texto\n",
        "  Sua expertise consiste em identificar padrões de mensagens nos chats e classificá-los nos mais diversos contextos.\n",
        "  Irá fazer uma análise do padrão de conversação do Ator desejado nos diferentes contextos em que se encontra\n",
        "  \"\"\",\n",
        "  backstory=\"\"\"\n",
        "  Você trabalha em um departamento de análise de mensagen, analisando e classificando textos de mensagens.\n",
        "  Sua expertise consiste em identificar padrões de mensagens e classificá-los nos mais diversos contextos.\n",
        "  Você deve ser capaz de identificar as nuncaes de comunicação do Ator alvo com coisas como:\n",
        "\n",
        "  - se sempre inicia suas mensagens com determinados padrões\n",
        "  - suas opiniões sobre os mais diversos assuntos e se mantem esse padrão em todos os contextos\n",
        "  - como ele reage a diversas interações nos diferentes contextos de conversas\n",
        "\n",
        "  Suas análises devem sempre ser conectadas a realidade das conversas que você teve acesso e no máximo pode fazer sugestões\n",
        "  de como o ator poderia reagir em outros contextos, com base em seu padrão de mensagens mas sempre que fizer isso sinalize que está fazendo isso.\n",
        "  \"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  llm = llm,\n",
        "  tools=[ readDirectoryTool ],\n",
        ")\n",
        "\n",
        "copycat_agent = Agent(\n",
        "  role='Imitador de padrões de conversa',\n",
        "  goal=f\"\"\"\n",
        "  Dado um conjunto de mensagens de texto\n",
        "  E dado um determinado Ator a ser copiado\n",
        "  Sua expertise consiste em imitar os padrões de mensagens nos chats nos mais diversos contextos de conversa.\n",
        "  Deve identificar e adotar o tom adequado de conversa, SEMPRE seguindo o padrão de conversas do Ator\n",
        "  Leve em muita consideração o perfil traçado pelo Agente analista de perfil.\n",
        "  \"\"\",\n",
        "  backstory=\"\"\"\n",
        "  Você é um imitador profissional.\n",
        "  Sua expertise consiste em identificar o contexto de uma mensagem e responder usando o padrão de mensagens do Ator copiado.\n",
        "  Você deve ser capaz de identificar as nuncaes de comunicação do Ator e imitar com máxima perfeição.\n",
        "  Suas respostas devem sempre ser conectadas a realidade das conversas que você teve acesso e no máximo pode fazer poucas modificações para dar maior fluidez e naturalidade a conversa.\n",
        "  \"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  llm = llm,\n",
        "  tools=[ readDirectoryTool ],\n",
        ")\n",
        "\n",
        "def make_profile_analisy_task(target_actor, conversations_folder='/content/Conversas', assigned_agent=profiler_agent):\n",
        "  return Task(\n",
        "      agent=assigned_agent,\n",
        "      description=f\"\"\"\n",
        "      Conduza uma análise de todos os arquivos de texto na pasta de conversas.\n",
        "      Identifique os pontos-chave dos padrões de conversação do {target_actor} e salve-os em seu contexto para uso futuro.\n",
        "      \"\"\",\n",
        "      expected_output = f\"\"\"\n",
        "      Sua resposta final DEVE ser um relatório completo sobre o padrão de conversas do Ator contendo:\n",
        "      - Os diferentes contextos em que {target_actor} se encontra\n",
        "      - Exemplos de como {target_actor} inicia suas conversas nos diferentes contextos\n",
        "      - Insight sobre a personalidade de {target_actor}\n",
        "      - Faça uma cópia de sua análise em formato Markdown no seguinte arquivo de saída  /content/sample_data/profiler_analyst/{target_actor}_profiled.md, se o arquivo não existir, crie ele salve seu relatório Markdown nele.\n",
        "\n",
        "      Sua resposta deve ser em Portugues do Brasil com um padrão de resposta formal e técnico.\n",
        "      \"\"\"\n",
        "  )\n",
        "\n",
        "def start_chat(target_actor, context='relação de amizade não tão próxima e com humor neutro', conversations_folder='/content/Conversas', assigned_agent=copycat_agent):\n",
        "  return Task(\n",
        "      agent=assigned_agent,\n",
        "      description=f\"\"\"\n",
        "      Deve iniciar uma convesa como {target_actor} usando os seus padrões de mensagem.\n",
        "      Use para esse inicio de mensagem um padrão de contexto {context} ou mais próximo disso que conseguir.\n",
        "      \"\"\",\n",
        "      expected_output = f\"\"\"\n",
        "      Sua resposta final DEVE ser uma unica mensagem de inicio de conversa como {target_actor} no contexto {context}.\n",
        "      \"\"\"\n",
        "  )\n",
        "\n",
        "def responds_chat(target_actor, message, conversations_folder='/content/Conversas', assigned_agent=copycat_agent):\n",
        "  return Task(\n",
        "      agent=assigned_agent,\n",
        "      description=f\"\"\"\n",
        "      Deve uma mensagem se passando por {target_actor} usando os seus padrões de mensagem.\n",
        "      Se atente ao contexto de toda a conversa E\n",
        "      Use um ton na resposta de acordo com a contexto ou mais próximo disso que conseguir.\n",
        "      Se você receber como resposta alguma coisa que não puder comentar ou um texto ofensivo que não puder responder, use o padrão de mensagens de {target_actor} evitar a resposta\n",
        "      Se você receber como resposta alguma contendo '\\bye', use o padrão de mensagens de {target_actor} para se despedir.\n",
        "      \"\"\",\n",
        "      expected_output = f\"\"\"\n",
        "      Sua resposta final DEVE ser uma unica mensagem de resposta a mensage {message}.\n",
        "      \"\"\"\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "id": "fMp1F-RUG7ke"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "\n",
        "print(\"## Welcome to the Be Right Back Social Network\")\n",
        "print('----------------------------------------------')\n",
        "print(f\"** WARN: Before continue, please make sure you have already uploaded the conversation file **\")\n",
        "print(\"System ~: hangind to use: [pt-br]...\")\n",
        "print(\"System ~:Pronto, agora falamos em seu idioma nativo, vamos iniciar\")\n",
        "\n",
        "target_actor = input(\"System ~:- 1. Quem é o ator alvo da análise (nome que usa no whatsapp)?\\n\")\n",
        "chats_folder = '/content/Conversas'\n",
        "print(\"System ~: Ok! Passei as informações ai setor de análise de perfis\")\n",
        "\n",
        "crew_profiling = Crew(\n",
        "    agents=[profiler_agent],\n",
        "    tasks=[make_profile_analisy_task(target_actor)],\n",
        "    verbose=2,\n",
        "    process=Process.sequential\n",
        ")\n",
        "result = crew_profiling.kickoff()\n",
        "print(result)\n",
        "\n",
        "\n",
        "print(\"System~: Me preparando...\")\n",
        "crew_start_message = Crew(\n",
        "    agents=[copycat_agent],\n",
        "    tasks=[start_chat(target_actor)],\n",
        "    verbose=0,\n",
        "    process=Process.sequential\n",
        ")\n",
        "\n",
        "#TODO: Changes to responds in JSON\n",
        "def crew_responds_message(actor, message):\n",
        "  crew = Crew(\n",
        "      agents=[copycat_agent],\n",
        "      tasks=[responds_chat(target_actor, message)],\n",
        "      verbose=0,\n",
        "      process=Process.sequential\n",
        "  )\n",
        "  answer = crew.kickoff()\n",
        "  return answer\n",
        "\n",
        "start_message = crew_start_message.kickoff()\n",
        "print(\"System~: Pronto, vamos lá! Quando desejar encerrar o chat digite: '\\\\bye'.\")\n",
        "\n",
        "received_message = input(f\"@{target_actor} ~: ${start_message} \\n\")\n",
        "\n",
        "#TODO: Improve it using generator function w/ yield instead of loop\n",
        "while True:\n",
        "  if '\\bye' in received_message:\n",
        "    model_answer = crew_responds_message(target_actor, received_message)\n",
        "    print(model_answer)\n",
        "    break\n",
        "\n",
        "  model_answer = crew_responds_message(target_actor, received_message)\n",
        "  received_message = input(f\"@{target_actor} ~: ${model_answer}\")\n",
        "\n",
        "print(\"System~: Obrigado por utilizar o serviço da BRB, até a próxima\")"
      ],
      "metadata": {
        "id": "QCudhVr4LBLO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}